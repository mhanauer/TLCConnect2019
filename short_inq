---
title: "TLC Connect 2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##################
Data cleaning
###############
Completed on 10-9-20
```{r}
library(prettyR)
setwd("P:/Evaluation/TN Lives Count_Connect/Databases")
tlc_data = read.csv("TLCConnect_10_1_2019.csv", header = TRUE, na.strings = c(-6,-7,-8,-9))
head(tlc_data)
## Change youth id 
colnames(tlc_data)[1] = "YouthID"
head(tlc_data)


describe.factor(tlc_data$CSSRS1)
describe.factor(tlc_data$CSSRS4)
describe.factor(tlc_data$AttemptSuicide)
head(tlc_data)
tlc_data_analysis = tlc_data[,c(1,2,5:9, 11, 13:56, 69:112,118,124)]
tlc_data_analysis = data.frame(tlc_data_analysis, HoursPsychotherapy = tlc_data$HoursPsychotherapy, CurrentlyEngaged  =  tlc_data$CurrentlyEngaged, ReferralsEngaged = tlc_data$ReferralsEngaged, Attend75Referrals = tlc_data$Attend75Referrals, ReferralsProvided = tlc_data$ReferralsProvided, CrisisPlan80Time = tlc_data$CrisisPlan80Time)
head(tlc_data_analysis)
#Check all variables are within the ranges
tlc_data_analysis$INQ6_B[tlc_data_analysis$INQ6_B == 8] = NA
apply(tlc_data_analysis[-c(1)], 2, function(x){describe.factor(x,decr.order = FALSE)})
head(tlc_data_analysis)

### Generate average scores
head(tlc_data_analysis)

### Get rid of missing treatments
tlc_data_analysis$treat_missing = is.na(tlc_data_analysis$TXPackageAssigned)
tlc_data_analysis = subset(tlc_data_analysis, treat_missing == FALSE)
dim(tlc_data_analysis)
tlc_data_analysis$treat_missing = NULL

#f = 6, g = 7, h = 8, I = 9,  j = 10, k = 11, l = 12, m = 13, t = 20
RAS_b_average = tlc_data_analysis[,9:28]

RAS_b_1_average = RAS_b_average[,c(6:13,20)]
RAS_b_1_average = apply(RAS_b_1_average, 1, mean, na.rm = TRUE)

#q=17,r=18,s=19
RAS_b_2_average = RAS_b_average[,17:19]
RAS_b_2_average = apply(RAS_b_2_average, 1, mean, na.rm = TRUE)

#a,b,c,d,e
RAS_b_3_average = RAS_b_average[,1:5]
RAS_b_3_average = apply(RAS_b_3_average, 1, mean, na.rm = TRUE)
#n=14,o=15,p=16
RAS_b_5_average = RAS_b_average[,14:16]
RAS_b_5_average = apply(RAS_b_5_average, 1, mean, na.rm = TRUE)

INQ_b_1_average = tlc_data_analysis[,29:34]
INQ_b_1_average = apply(INQ_b_1_average, 1, mean, na.rm = TRUE)

INQ_b_2_average = tlc_data_analysis[,35:40]

#https://www.marsja.se/reverse-scoring-using-r/
INQ_b_2_average = 8-INQ_b_2_average
INQ_b_2_average = apply(INQ_b_2_average,1, mean, na.rm = TRUE)

SSMI_b_average = tlc_data_analysis[,41:45]
SSMI_b_average =  apply(SSMI_b_average, 1, mean, na.rm = TRUE)



SIS_b_average = tlc_data_analysis[,46:52]

#a,b,c,d
SIS_b_1_average = SIS_b_average[,1:4]
SIS_b_1_average = apply(SIS_b_1_average, 1, mean, na.rm =TRUE)

#e,f,g
SIS_b_2_average = SIS_b_average[,5:7]
SIS_b_2_average = apply(SIS_b_2_average, 1, mean, na.rm =TRUE)



#### Discharge
#f = 6, g = 7, h = 8, I = 9,  j = 10, k = 11, l = 12, m = 13, t = 20
RAS_d_average = tlc_data_analysis[53:72]

RAS_d_1_average = RAS_d_average[,c(6:13,20)]
RAS_d_1_average = apply(RAS_d_1_average, 1, mean, na.rm = TRUE)

#q=17,r=18,s=19
RAS_d_2_average = RAS_d_average[,17:19]
RAS_d_2_average = apply(RAS_d_2_average, 1, mean, na.rm = TRUE)

#a,b,c,d,e
RAS_d_3_average = RAS_d_average[,1:5]
RAS_d_3_average = apply(RAS_d_3_average, 1, mean, na.rm = TRUE)
#n=14,o=15,p=16
RAS_d_5_average = RAS_d_average[,14:16]
RAS_d_5_average = apply(RAS_d_5_average, 1, mean, na.rm = TRUE)

INQ_d_1_average = tlc_data_analysis[,73:78]
INQ_d_1_average = apply(INQ_d_1_average, 1, mean, na.rm = TRUE)

INQ_d_2_average = tlc_data_analysis[,79:84]
INQ_d_2_average = 8-INQ_d_2_average
INQ_d_2_average = apply(INQ_d_2_average, 1, mean, na.rm = TRUE)

SSMI_d_average = tlc_data_analysis[,85:89]
SSMI_d_average =  apply(SSMI_d_average, 1, mean, na.rm = TRUE)


SIS_d_average = tlc_data_analysis[,90:96]

#a,b,c,d
SIS_d_1_average = SIS_d_average[,1:4]
SIS_d_1_average = apply(SIS_d_1_average, 1, mean, na.rm =TRUE)

#e,f,g
SIS_d_2_average = SIS_d_average[,5:7]
SIS_d_2_average = apply(SIS_d_2_average, 1, mean, na.rm =TRUE)

### Create difference scores
RAS_1_diff = RAS_d_1_average - RAS_b_1_average
RAS_2_diff = RAS_d_2_average - RAS_b_2_average
RAS_3_diff = RAS_d_3_average - RAS_b_3_average
RAS_5_diff = RAS_d_5_average - RAS_b_5_average



INQ_1_diff = INQ_d_1_average - INQ_b_1_average
INQ_2_diff = INQ_d_2_average - INQ_b_2_average
SSMI_diff = SSMI_d_average-SSMI_b_average

SIS_1_diff = SIS_d_1_average-SIS_b_1_average
SIS_2_diff = SIS_d_2_average-SIS_b_2_average

PHQ9_b = tlc_data_analysis$PHQ9_1
PHQ9_d = tlc_data_analysis$PHQ9_4
PHQ9_diff = tlc_data_analysis$PHQ9_4 - tlc_data_analysis$PHQ9_1

#### Create new data with average scores
#apply(tlc_data_analysis, 2, function(x){describe.factor(x)})
tlc_data_analysis_average = data.frame(tlc_data_analysis[,c(1,2,4:8, 99:104)], RAS_b_1_average, RAS_b_2_average, RAS_b_3_average, RAS_b_5_average, INQ_b_1_average, INQ_b_2_average, SSMI_b_average, SIS_b_1_average, SIS_b_2_average, PHQ9_b = tlc_data_analysis$PHQ9_1,RAS_d_1_average, RAS_d_2_average, RAS_d_3_average, RAS_d_5_average, INQ_d_1_average, INQ_d_2_average, SSMI_d_average, SIS_d_1_average, SIS_d_2_average,PHQ9_d = tlc_data_analysis$PHQ9_4)




### Get rid of EHR vars and PHQ
tlc_data_analysis_average[,c(8:13, 23,33)] = NULL
tlc_psycho=  tlc_data_analysis
dim(tlc_psycho)
```

Just omegas for each construct

model_2  ='INQ12_1 =~ INQ1_B + INQ2_B  + INQ4_B
          INQ12_2 =~  INQ9_B+ INQ11_B + INQ10_B'
```{r}
library(psych)

RAS_b_pyscho = tlc_data_analysis[,9:28]
RAS_b_1_pyscho = RAS_b_pyscho[,c(6:13,20)]

RAS_b_2_pyscho = RAS_b_pyscho[,17:19]

RAS_b_3_pyscho = RAS_b_pyscho[,1:5]

RAS_b_5_pyscho = RAS_b_pyscho[,14:16]



SSMI_b_pyscho = tlc_data_analysis[,41:45]

SIS_b_pyscho = tlc_data_analysis[,46:52]

SIS_b_1_pyscho = SIS_b_pyscho[,1:4]


SIS_b_2_pyscho = SIS_b_pyscho[,5:7]

INQ_b_1_pyscho = tlc_data_analysis[,c(29:30, 32)]
summary(omega(INQ_b_1_pyscho, poly = TRUE))

INQ_b_2_pyscho = tlc_data_analysis[,37:39]
INQ_b_2_pyscho = 8-INQ_b_2_pyscho
summary(omega(INQ_b_2_pyscho, poly = TRUE))


```



Pyschometrics
Test confirmatory factor because we have support that should be one factor
Then do invar and see if related to any factors that you included

See Hirschfeld(2014) for details

```{r}
head(tlc_psycho)
INQ_b_average = tlc_psycho[,c(29:30, 32, 37:39)]
INQ_b_average$ID = 1:dim(INQ_b_average)[1]
## Create a variable without any missing data
library(caret)
set.seed(123)
inTrain = createDataPartition(y = INQ_b_average$ID, p = .50, list = FALSE)
efa_b_inq = INQ_b_average[inTrain,]
cfa_b_inq = INQ_b_average[-inTrain,]
efa_b_inq$ID = NULL
cfa_b_inq$ID = NULL
INQ_b_average$ID = NULL

library(psych)
# Poly cor produces errors
efa_b_1 = fa(r = efa_b_inq, nfactors = 1, fm = "gls")
efa_b_2 = fa(r = efa_b_inq, nfactors = 2, fm = "gls")
efa_b_3 = fa(r = efa_b_inq, nfactors = 3, fm = "gls")

anova(efa_b_1, efa_b_2)
anova(efa_b_2, efa_b_3)
fa.diagram(efa_b_2)
### Need three items for measurement invariance
fa.diagram(efa_b_3)

####
vss(efa_b_inq, rotate = "oblimin")
###
fa.parallel(efa_b_inq, fm = "gls", fa = "fa")

### Try CFA

library(lavaan)
model_2  ='INQ12_1 =~ INQ1_B + INQ2_B + INQ3_B + INQ4_B + INQ5_B + INQ6_B
          INQ12_2 =~ INQ7_B + INQ8_B + INQ9_B+ INQ10_B + INQ10_B + INQ11_B + INQ12_B'

fit_2 = cfa(model_2, estimator = "WLSMVS", data = cfa_b_inq, ordered = TRUE)
summary(fit_2, fit.measures = TRUE, standardized = TRUE)


```
Try reducing the number of items by three each based on 2 factor EFA with the lowest standardized factor loadings
```{r}
library(lavaan)
model_2  ='INQ12_1 =~ INQ1_B + INQ2_B  + INQ4_B
          INQ12_2 =~  INQ9_B+ INQ11_B + INQ10_B'

fit_2 = cfa(model_2, estimator = "WLSMVS", data = cfa_b_inq, ordered = TRUE)
summary(fit_2, fit.measures = TRUE, standardized = TRUE)
```


Measurement invariance
```{r}
### Measurement invariance at base for everything besides time 
library(semTools)

model_2  ='INQ12_1 =~ INQ1_B + INQ2_B  + INQ4_B
          INQ12_2 =~  INQ9_B+ INQ11_B + INQ10_B'
head(tlc_data_analysis)
measure_invar = tlc_data_analysis
head(measure_invar)
measure_invar$HispanicLatino = ifelse(measure_invar$HispanicLatino == 2, NA, measure_invar$HispanicLatino)
describe.factor(measure_invar$HispanicLatino)
describe.factor(measure_invar$RaceEthnicity)
### Non-white versus white
measure_invar$RaceEthnicity = ifelse(measure_invar$RaceEthnicity != 3, 0, 1)
describe.factor(measure_invar$Version)
###sexual minority versus white
describe.factor(measure_invar$SexualOrientation)
measure_invar$SexualOrientation = ifelse(measure_invar$SexualOrientation != 5, 0,1)
measure_invar$Age = as.numeric(measure_invar$Age)
## Greater than the average age so "older" youth
measure_invar$Age = ifelse(measure_invar$Age > mean(measure_invar$Age, na.rm = TRUE), 1, 0)
#female
measure_invar$Gender = ifelse(measure_invar$Gender == 1, 0, 1)

measure_invar_config = list()
measure_invar_weak = list()
measure_invar_strong = list()
measure_invar_strict = list()
anova_results = list()
measure_invar_names = names(measure_invar)[4:8]
for(i in 1:length(measure_invar_names)){
 measure_invar_config[[i]]= cfa(model_2, data = measure_invar, group = measure_invar_names[[i]], estimator = "MLR", missing = "ML")
 measure_invar_weak[[i]]= cfa(model_2, data = measure_invar, group = measure_invar_names[[i]], estimator = "MLR", missing = "ML", group.equal="loadings")
 measure_invar_strong[[i]]= cfa(model_2, data = measure_invar, group = measure_invar_names[[i]], estimator = "MLR", missing = "ML", group.equal=c("loadings", "intercepts"))
 measure_invar_strict[[i]]= cfa(model_2, data = measure_invar, group = measure_invar_names[[i]], estimator = "MLR", missing = "ML", group.equal=c("loadings", "intercepts", "residuals"))
 anova_results[[i]] = anova(measure_invar_config[[i]], measure_invar_weak[[i]], measure_invar_strong[[i]], measure_invar_strict[[i]])
}
anova_results
```




Concurrent and predictive with suicideal ideation
Get all three measures into total scores and then one data set
```{r}
con_pred = data.frame(INQ_b_1_average, INQ_b_2_average, SIS_b_1_average, SIS_b_2_average, SIS_d_1_average, SIS_d_2_average)
head(con_pred)
library(Hmisc)
rcorr(as.matrix(con_pred), type = "spearman")
```

Get Measurement invar over time

model_2  ='INQ12_1 =~ INQ1_B + INQ2_B  + INQ4_B
          INQ12_2 =~  INQ9_B+ INQ11_B + INQ10_B'

```{r}
measure_invar = tlc_data_analysis
measure_invar = tlc_data_analysis
INQ_b_1 = measure_invar[,29:34]
INQ_b_1$id = rep(0, dim(INQ_b_1)[1])

INQ_b_2 = measure_invar[,35:40]
INQ_b_2 = 8-INQ_b_2
INQ_b_2$id = rep(0, dim(INQ_b_2)[1])

INQ_d_1 = measure_invar[,73:78]
INQ_d_1$id = rep(1, dim(INQ_d_1)[1])

INQ_d_2 = measure_invar[,79:84]
INQ_d_2$id = rep(1, dim(INQ_d_2)[1])

## Change names to be the same then rbind
colnames(INQ_d_1) = colnames(INQ_b_1)
colnames(INQ_d_2) = colnames(INQ_b_2)

INQ_b_d_1 = rbind(INQ_b_1, INQ_d_1)
INQ_b_d_2 = rbind(INQ_b_2, INQ_d_2)
INQ_b_d = cbind(INQ_b_d_1, INQ_b_d_2)
INQ_b_d
```
Now invar with time
```{r}
measure_invar_config = list()
measure_invar_weak = list()
measure_invar_strong = list()
measure_invar_strict = list()
anova_results = list()
library(lavaan)

model_2  ='INQ12_1 =~ INQ1_B + INQ2_B  + INQ4_B
          INQ12_2 =~  INQ9_B+ INQ11_B + INQ10_B'


measure_invar_names = names(INQ_b_d)[14]
for(i in 1:length(measure_invar_names)){
 measure_invar_config[[i]]= cfa(model_2, data = INQ_b_d[,c(1, 2, 4, 10,11, 12, 7)], group = measure_invar_names[[i]], estimator = "MLR", missing = "ML")
 measure_invar_weak[[i]]= cfa(model_2, data = INQ_b_d[,c(1, 2, 4, 9, 11,10)], group = measure_invar_names[[i]], estimator = "MLR", missing = "ML", group.equal="loadings")
 measure_invar_strong[[i]]= cfa(model_2, data = INQ_b_d[,c(1, 2, 4, 9, 11,10)], group = measure_invar_names[[i]], estimator = "MLR", missing = "ML", group.equal=c("loadings", "intercepts"))
 measure_invar_strict[[i]]= cfa(model_2, data = INQ_b_d[,c(1, 2, 4, 9, 11,10)], group = measure_invar_names[[i]], estimator = "MLR", missing = "ML", group.equal=c("loadings", "intercepts", "residuals"))
 anova_results[[i]] = anova(measure_invar_config[[i]], measure_invar_weak[[i]], measure_invar_strong[[i]], measure_invar_strict[[i]])
}
anova_results

```
Get reliability for two factors, test-retest 
```{r}
inq12_b_fac1 = measure_invar[,29:34]
inq12_b_fac1_mean = apply(inq12_b_fac1, 1, mean, na.rm = TRUE)
inq12_b_fac2 = measure_invar[,35:40]
inq12_b_fac2_mean = apply(inq12_b_fac2, 1, mean, na.rm = TRUE)


inq12_d_fac1 = measure_invar[,73:78]
inq12_d_fac1_mean = apply(inq12_d_fac1, 1, mean, na.rm = TRUE)
inq12_d_fac2 = measure_invar[,79:84]
inq12_d_fac2_mean = apply(inq12_d_fac2, 1, mean, na.rm = TRUE)

summary(omega(inq12_b_fac1))
summary(omega(inq12_b_fac2))


hist(inq12_b_fac1_mean)
qqnorm(inq12_b_fac1_mean)

length(inq12_d_fac1_mean)
n_1 = data.frame(inq12_b_fac1_mean, inq12_d_fac1_mean)
dim(na.omit(n_1))
n_2 = data.frame(inq12_b_fac2_mean,inq12_d_fac2_mean)
dim(na.omit(n_2))
cor.test(inq12_b_fac1_mean, inq12_d_fac1_mean, method = "spearman")
cor.test(inq12_b_fac2_mean, inq12_d_fac2_mean, method = "spearman")
```
###################################
IRT analyses
###################################
Make sure reverse scoring is applied correctly

Create the data sets first
INQ_b_1_pyscho = tlc_data_analysis[,29:34]
INQ_b_2_pyscho = tlc_data_analysis[,35:40]
```{r}
irt_inq_b = tlc_psycho[,c(29:40)]
irt_inq_d = tlc_psycho[,c(73:84)]
names(irt_inq_d) = names(irt_inq_b)
irt_inq = rbind(irt_inq_b, irt_inq_d)
irt_inq
irt_inq[,c(7:12)] = 8 - irt_inq[,c(7:12)] 
irt_inq
### Need to stack half of the variables
library(naniar)
library(prettyR)
describe.factor(irt_inq$INQ6_B)
dim(irt_inq_b)[1]
dim(irt_inq_d)[1]
#apply(irt_inq, 2, function(x){prettyR::describe.factor(x, decr.order = FALSE)})
```
Maybe try dicot and see if results are better
```{r}
library(mirt)
#######################################################################
######################################################################
#fitting IRT model - graded
INQ_b_graded = mirt(irt_inq, model = 2, itemtype = "graded", technical=list(removeEmptyRows=TRUE))
INQ_b_graded


#INQ_b_graded_pcm = mirt(irt_inq, model=model_INQ_b, itemtype = "Rasch", technical=list(removeEmptyRows=TRUE))

#INQ_b_graded_gpcm<-mirt(irt_inq, model=model_INQ_b, itemtype = "gpcm", technical=list(removeEmptyRows=TRUE))

#anova(INQ_b_graded,INQ_b_graded_pcm)
#anova(INQ_b_graded_pcm,INQ_b_graded_gpcm)

```
Get overall model fit and plot
```{r}
INQ_b_graded_fit  = M2(INQ_b_graded, type='C2', na.rm=TRUE, theta_lim = c(-3, 3), CI = .95)
INQ_b_graded_fit
summary(INQ_b_graded, suppress = 0.25)
plot(INQ_b_graded, type = "score", rotate = "promax", theta_lim  = c(-3, 3))

```
Item level grm fit
```{r}
INQ_b_graded_grm_fit<-itemfit(INQ_b_graded, na.rm=TRUE)

INQ_b_graded_grm_fit[,2:4] =round(as.matrix(INQ_b_graded_grm_fit[,2:4]), digits=3)
INQ_b_graded_grm_fit_results = INQ_b_graded_grm_fit
p_values <- INQ_b_graded_grm_fit_results[,5] #p values are stored in 5th column 
p_values
p_values_adj <-p.adjust(p_values, method="BH")
p_values_adj =  round(p_values_adj, digits=3)
#combined item fit
results<-cbind(INQ_b_graded_grm_fit_results, p_values_adj)
results
```
Now getting coefficients and plotting
A coefs are the spots on the dimensions where the item is most discriminating.

```{r}
#getting out coefficients
INQ_b_graded_coef <- coef(INQ_b_graded, rotate = 'promax', simplify = TRUE)
INQ_b_graded_coef

list_plots = list()
count_plots = 1:12
for(i in 1:length(count_plots)){
  list_plots[[i]] = itemplot(INQ_b_graded,item=count_plots[[i]], rotate = "promax", type="score", theta_lim = c(-3,3))
}
list_plots
```
Test this
```{r}
## Not run:
dat <- expand.table(LSAT7)
x <- mirt(dat, 1)
coef(x)
coef(x, IRTpars = TRUE)
coef(x, simplify = TRUE)
#with computed information matrix
x <- mirt(dat, 1, SE = TRUE)
coef(x)
coef(x, printSE = TRUE)
coef(x, as.data.frame = TRUE)
#two factors
x2 <- mirt(Science, 2)
coef(x2)
coef(x2, rotate = 'varimax', simplify = TRUE)

```

